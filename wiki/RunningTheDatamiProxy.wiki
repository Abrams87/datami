Instruction to install, configure and run the datami-proxy to collect information about the user's web activities

The datami-proxy is at the basis of the DATAMI application. It takes the form of a Web proxy, installed on the user's local computer, and that logs information about HTTP requests and responses in and RDF triple store, to be processed by other parts of the DATAMI architecture. 

= What it does and what it builds on =

The datami-proxy is a logging Web proxy. It intercepts Web traffic going in and out of the user's computer and collect information about this traffic. It differs however from standard Web proxies as 1- it stores the information in a semantic web compatible format, using an RDF triple store, and 2- it stores different types of information. Indeed, standard logging proxy would store in a text format mostly information about the URLs accessed, their parameters and time. In our case, we also need to log the textual content of the response, in order to be able to analyze it to extract common entities the user interacts with. 

To realize that, datami-proxy relies on the [http://jetty.codehaus.org/jetty/ Jetty] web application server to capture Web traffic and retransmit it to its intended destination. As it does that, it collects information about the proxy and send it to a running triple store, using the [http://www.w3.org/TR/sparql11-update/ SPARQL Update protocol]. Different types of triple stores implementing the SPARQL Update protocal are available. We generally use [http://incubator.apache.org/jena/documentation/serving_data/ Fuseki], as it is self-contain, easy to set-up and reasonably lightweight in terms of memory consumption.

In addition, as keeping all the data and processing them on the local computer of the user might not be convenient, the datami-proxy can be set-up to synchronize and clear the content of the local triple store at regular intervals, therefore using the local triple store only as a temporary buffer.

= Setting up and running the datami-proxy =

== Getting the sources and compiling ==

The sources of the datami-proxy are available from the public SVN of the DATAMI Google code repository (see [ http://code.google.com/p/datami/source/browse/#svn%2Ftrunk%2Fdatami-proxy the datami-proxy directory]). 

A simple [http://code.google.com/p/datami/source/browse/trunk/datami-proxy/compile.sh compilation shell script (bash)] is also provided.

== Setting up the local triple store ==

As mentioned above, any triple store that implements SPARQL Update can be used with datami-proxy. The only requirement is that it should be started separately and be running when the datami-proxy starts.

In out installations, we use Fuseki (see link above), which can easily be downloaded and installed. An [http://code.google.com/p/datami/source/browse/trunk/datami-proxy/run-fuseki.sh example script] is provide to start Fuseki (assuming it hes been installed in a directory named "Fuseki-0.2.0"). 

== Configuring the datami-proxy ==

Configuring the datami-proxy is done through the [http://code.google.com/p/datami/source/browse/trunk/datami-proxy/wllproxy.properties wllproxy.properties] configuration file. The element be included are:
  * (Optional) If computer of the user usually access the internet through a proxy, the host and port of this proxy
  * The URL of the SPARQL Update endpoint from the local triple-store
  * The URL of the SPARQL Query endpoint from the local triple-store
  * The URL of the SPARQL Update endpoint of the external triple-store for synchronization 
  * The synchronization delay (in seconds, default: 1800)
  * The username (all alpha-numerical characters) to include in the data

== Running the datami-proxy ==

A very simple [ shell script (bash)] is provided to run the datami-proxy. Note however that, on most system, this would require to be run by an admin user (using "sudo"). Also, it is preferable to ensure that the proxy will continue to run if the terminal was closed (using "nohup").

== Configuring the computer/browser to use datami-proxy ==

In order for the Web traffic generated by the user to be directed to the datami-proxy, the computer and/or Web browsers used need to be configured. For example, in Firefox, this can be done by:
  # Going to the preference pannel
  # Going to the "Advanced" tab
  # Choosing the "Network" sub-tab
  # Clicking on the "Settings..." button
  # Choosing "Manual proxy configuration" (if not already done)
  # Untick the "Use this proxy server for all protocols" box
  # Changing the "HTTP proxy" fields to "127.0.0.1" and "80" (or the port used when starting the datami-proxy)
  # Ensure that the "No Proxy for:" field includes at least localhost or 127.0.0.1, as well as the domain name of the machine where the external triple store is installed
  # Leave the other fields blank, or with their previous values

Most other browsers (Chrome, Safari, IE) would use the systems configuration for proxies. Changing this configuration depends on the operating systems. For example, on MacOS X, in the network section of the system preferences, the proxy can be setup for each connection by clicking the "Advanced..." button, going to the "Proxies" tab, and indicating "127.0.0.1" and "80" for the "Web Proxy (HTTP)" configuration.

= Bugs and limitations =

The current version of the datami-proxy is a development version. It is sufficiently robust to handle the Web traffic of an average user, but suffer from a number of limitations which might affect the Web experience of users. Mostly:
  * It does not handle cookies and sessions properly. This means that it might affect the user's ability to connect onto websites that require authentication.
  * It does not handle referrers properly. This would in most cases not affect the user's Web experience. 
  * It does not handle CONNECT request properly. CONNECT request are authentication requests used for SSL connections, but that are sent over HTTP. This means that the user might experience issues with connecting with SSL
  * It cannot be used to log HTTPS traffic.